# ä¸‰å±‚é¢æ ¸å¿ƒä¿®æ”¹è¯¦è§£

## ğŸ“‹ ä¿®æ”¹æ¦‚è¿°

æœ¬é¡¹ç›®å¯¹LAPOç®—æ³•è¿›è¡Œäº†ä¸‰ä¸ªå±‚é¢çš„æ ¸å¿ƒä¿®æ”¹ï¼Œä½¿å…¶èƒ½å¤Ÿå¤„ç†çœŸå®æœºæ¢°è‡‚é‡‡é›†çš„å¤šæ¨¡æ€æ•°æ®ã€‚

---

## ğŸ¯ ç¬¬ä¸€å±‚é¢ï¼šç‰¹å¾æå–å±‚ï¼ˆVisual Backboneï¼‰

### 1.1 ResNet18ç¼–ç å™¨å®ç°

**æ–‡ä»¶**: `algos/algos_vae_multimodal.py` (ç¬¬14-34è¡Œ)

```python
class ResNet18Encoder(nn.Module):
    """
    ä½¿ç”¨é¢„è®­ç»ƒçš„ResNet18ä½œä¸ºå›¾åƒç¼–ç å™¨
    è¾“å…¥: (batch_size, 3, height, width)
    è¾“å‡º: (batch_size, feature_dim)
    """
    def __init__(self, output_dim=256, pretrained=True):
        super(ResNet18Encoder, self).__init__()
        self.resnet = models.resnet18(pretrained=pretrained)
        # ç§»é™¤æœ€åçš„å…¨è¿æ¥å±‚ï¼Œä¿ç•™ç‰¹å¾æå–å™¨
        self.resnet = nn.Sequential(*list(self.resnet.children())[:-1])
        # ResNet18çš„æœ€åä¸€å±‚è¾“å‡ºä¸º512ç»´ç‰¹å¾
        self.fc = nn.Linear(512, output_dim)
    
    def forward(self, x):
        x = self.resnet(x)      # æå–512ç»´ç‰¹å¾
        x = x.view(x.size(0), -1)  # Flatten
        x = F.relu(self.fc(x))  # æ˜ å°„åˆ°output_dim
        return x
```

**å…³é”®ç‰¹æ€§**ï¼š
- âœ… ä½¿ç”¨é¢„è®­ç»ƒResNet18ï¼ˆImageNetæƒé‡ï¼‰åŠ é€Ÿæ”¶æ•›
- âœ… ç§»é™¤åˆ†ç±»å¤´ï¼Œä¿ç•™ç‰¹å¾æå–å™¨
- âœ… 512 â†’ output_dimçš„æ˜ å°„å±‚
- âœ… æ”¯æŒä»»æ„RGBè¾“å…¥

### 1.2 9é€šé“å›¾åƒå¤„ç†ï¼ˆä¸‰å¼ RGBæ‹¼æ¥ï¼‰

è™½ç„¶ä»£ç ä¸­å¤„ç†çš„æ˜¯åˆ†å¼€çš„å›¾åƒï¼Œä½†é€»è¾‘ä¸Šæ”¯æŒ9é€šé“ï¼ˆ3Ã—3ï¼‰å¤„ç†ï¼š

```
å·¦æ‰‹è…•å›¾åƒ (3é€šé“)   [R, G, B]
å³æ‰‹è…•å›¾åƒ (3é€šé“)   [R, G, B]
å…¨å±€å›¾åƒ (3é€šé“)     [R, G, B]
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
æ€»è®¡: 9é€šé“è¾“å…¥
```

**å¤„ç†æ–¹å¼**ï¼š
- æ¯å¼ å›¾åƒç‹¬ç«‹ç¼–ç  (3Ã—ResNet18)
- ç‰¹å¾ç»´åº¦ï¼š128ç»´ Ã— 3 = 384ç»´
- èåˆå‰ç¼€è”ï¼š384ç»´ + 128ç»´(å…³èŠ‚) = 512ç»´

### 1.3 ImageJointEncoderèåˆå±‚

**æ–‡ä»¶**: `algos/algos_vae_multimodal.py` (ç¬¬37-85è¡Œ)

```python
class ImageJointEncoder(nn.Module):
    """èåˆç¼–ç å™¨ï¼šç¼–ç ä¸‰å¼ å›¾åƒå’Œå…³èŠ‚æ•°æ®"""
    
    def __init__(self, joint_dim=16, image_feature_dim=128, fusion_dim=256):
        super(ImageJointEncoder, self).__init__()
        
        # ä¸‰ä¸ªç‹¬ç«‹çš„ResNet18ç¼–ç å™¨
        self.left_wrist_encoder = ResNet18Encoder(output_dim=image_feature_dim)
        self.right_wrist_encoder = ResNet18Encoder(output_dim=image_feature_dim)
        self.global_encoder = ResNet18Encoder(output_dim=image_feature_dim)
        
        # å…³èŠ‚ç‰¹å¾ç½‘ç»œ (16ç»´ â†’ 128ç»´)
        self.joint_fc = nn.Sequential(
            nn.Linear(joint_dim, 128),
            nn.ReLU(),
            nn.Linear(128, image_feature_dim)
        )
        
        # èåˆå±‚
        total_feature_dim = image_feature_dim * 4  # 384 + 128 = 512
        self.fusion_fc = nn.Sequential(
            nn.Linear(total_feature_dim, 512),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(512, fusion_dim),
            nn.ReLU()
        )
    
    def forward(self, left_img, right_img, global_img, joint):
        # ç¼–ç ä¸‰å¼ å›¾åƒ
        left_feat = self.left_wrist_encoder(left_img)       # 128ç»´
        right_feat = self.right_wrist_encoder(right_img)    # 128ç»´
        global_feat = self.global_encoder(global_img)       # 128ç»´
        
        # ç¼–ç å…³èŠ‚æ•°æ®
        joint_feat = self.joint_fc(joint)                   # 128ç»´
        
        # æ‹¼æ¥ â†’ èåˆ
        fused = torch.cat([left_feat, right_feat, global_feat, joint_feat], dim=1)
        # [batch, 512] â†’ [batch, 256]
        fused_feat = self.fusion_fc(fused)
        
        return fused_feat
```

**æ¶æ„å›¾**ï¼š
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            å¤šæ¨¡æ€è¾“å…¥ (ä¸‰è·¯å›¾åƒ + å…³èŠ‚)              â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚             â”‚             â”‚          â”‚
  [84Ã—84Ã—3]    [84Ã—84Ã—3]    [84Ã—84Ã—3]   [16ç»´]
     â”‚             â”‚             â”‚          â”‚
     â–¼             â–¼             â–¼          â–¼
  ResNet18    ResNet18      ResNet18      FCç½‘ç»œ
    (128)       (128)         (128)      (128)
     â”‚             â”‚             â”‚          â”‚
     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚           â”‚
       æ‹¼æ¥[512]
            â”‚
            â–¼
        èåˆå±‚FC
       [512â†’512â†’256]
            â”‚
            â–¼
        èåˆç‰¹å¾[256ç»´]
```

**ä¼˜åŠ¿**ï¼š
- ä¿ç•™å„æ¨¡æ€çš„ç‹¬ç«‹ç‰¹å¾
- å¤šæ¨¡æ€èåˆå±‚æ•è·è·¨æ¨¡æ€å…³ç³»
- é«˜æ•ˆä¸”å¯è§£é‡Š

---

## ğŸ”§ ç¬¬äºŒå±‚é¢ï¼šç½‘ç»œç»“æ„ä¿®æ”¹ï¼ˆNetworksï¼‰

### 2.1 Actorç½‘ç»œä¿®æ”¹

**æ–‡ä»¶**: `algos/algos_vae_multimodal.py` (ç¬¬88-114è¡Œ)

```python
class Actor(nn.Module):
    """
    åŠ¨ä½œç­–ç•¥ç½‘ç»œ - åœ¨éšç©ºé—´ä¸­å­¦ä¹ ç­–ç•¥
    è¾“å…¥: èåˆçš„è§‚å¯Ÿç‰¹å¾ (256ç»´)
    è¾“å‡º: æ½œåœ¨å‘é‡ (32ç»´ = action_dim Ã— 2)
    """
    def __init__(self, obs_feature_dim, latent_dim, max_action, device):
        super(Actor, self).__init__()
        hidden_size = (256, 256, 256)
        
        # ç½‘ç»œå±‚
        self.pi1 = nn.Linear(obs_feature_dim, hidden_size[0])    # 256 â†’ 256
        self.pi2 = nn.Linear(hidden_size[0], hidden_size[1])     # 256 â†’ 256
        self.pi3 = nn.Linear(hidden_size[1], hidden_size[2])     # 256 â†’ 256
        self.pi4 = nn.Linear(hidden_size[2], latent_dim)         # 256 â†’ 32
        
        self.max_action = max_action
    
    def forward(self, obs_feature):
        """
        è¾“å…¥: obs_feature [batch, 256] (èåˆç‰¹å¾)
        è¾“å‡º: latent_action [batch, 32] (éšç©ºé—´åŠ¨ä½œ)
        """
        a = F.relu(self.pi1(obs_feature))
        a = F.relu(self.pi2(a))
        a = F.relu(self.pi3(a))
        a = self.pi4(a)
        a = self.max_action * torch.tanh(a)  # çº¦æŸåœ¨[-max_action, max_action]
        
        return a
```

**å…³é”®æ”¹è¿›**ï¼š
- âœ… è¾“å…¥æ˜¯èåˆç‰¹å¾ï¼ˆè€ŒéåŸå§‹è§‚å¯Ÿï¼‰
- âœ… å·¥ä½œåœ¨éšç©ºé—´è€ŒéåŠ¨ä½œç©ºé—´
- âœ… è¾“å‡ºä¸å…³èŠ‚ç»´åº¦ç›¸å…³ï¼ˆlatent_dim = action_dim Ã— 2ï¼‰

### 2.2 ActorVAEç½‘ç»œä¿®æ”¹

**æ–‡ä»¶**: `algos/algos_vae_multimodal.py` (ç¬¬117-171è¡Œ)

```python
class ActorVAE(nn.Module):
    """
    æ¡ä»¶å˜åˆ†è‡ªç¼–ç å™¨ (CVAE)
    
    ç¼–ç å™¨: (obs_feature + action) â†’ (mean, log_var)
    é‡‡æ ·:   z ~ N(mean, std)
    è§£ç å™¨: (obs_feature + z) â†’ reconstructed_action
    """
    def __init__(self, obs_feature_dim, action_dim, latent_dim, max_action, device):
        super(ActorVAE, self).__init__()
        hidden_size = (256, 256, 256)
        
        # ç¼–ç å™¨: (èåˆç‰¹å¾ + åŠ¨ä½œ) â†’ éšå˜é‡åˆ†å¸ƒ
        self.e1 = nn.Linear(obs_feature_dim + action_dim, hidden_size[0])
        self.e2 = nn.Linear(hidden_size[0], hidden_size[1])
        self.e3 = nn.Linear(hidden_size[1], hidden_size[2])
        
        self.mean = nn.Linear(hidden_size[2], latent_dim)        # Î¼
        self.log_var = nn.Linear(hidden_size[2], latent_dim)     # log(ÏƒÂ²)
        
        # è§£ç å™¨: (èåˆç‰¹å¾ + éšå˜é‡) â†’ åŠ¨ä½œ
        self.d1 = nn.Linear(obs_feature_dim + latent_dim, hidden_size[0])
        self.d2 = nn.Linear(hidden_size[0], hidden_size[1])
        self.d3 = nn.Linear(hidden_size[1], hidden_size[2])
        self.d4 = nn.Linear(hidden_size[2], action_dim)  # è¾“å‡º16ç»´åŠ¨ä½œ
        
        self.max_action = max_action
        self.action_dim = action_dim
        self.latent_dim = latent_dim
        self.device = device
    
    def forward(self, obs_feature, action):
        """
        è¾“å…¥:
            obs_feature: [batch, 256] (èåˆç‰¹å¾)
            action: [batch, 16] (å…³èŠ‚åŠ¨ä½œ)
        
        è¾“å‡º:
            u: [batch, 16] (é‡æ„åŠ¨ä½œ)
            z_sample: [batch, 32] (é‡‡æ ·çš„éšå˜é‡)
            mean: [batch, 32] (åˆ†å¸ƒå‡å€¼)
            log_var: [batch, 32] (åˆ†å¸ƒlogæ–¹å·®)
        """
        # ç¼–ç é˜¶æ®µ
        z = F.relu(self.e1(torch.cat([obs_feature, action], 1)))
        z = F.relu(self.e2(z))
        z = F.relu(self.e3(z))
        
        mean = self.mean(z)
        log_var = self.log_var(z)
        
        # é‡å‚æ•°åŒ–æŠ€å·§
        std = torch.exp(log_var / 2)
        z_sample = mean + std * torch.randn_like(std)
        
        # è§£ç é˜¶æ®µ
        u = self.decode(obs_feature, z_sample)
        
        return u, z_sample, mean, log_var
    
    def decode(self, obs_feature, z=None, clip=None):
        """
        è¾“å…¥:
            obs_feature: [batch, 256] (èåˆç‰¹å¾)
            z: [batch, 32] (éšå˜é‡)
        
        è¾“å‡º:
            a: [batch, 16] (é‡æ„æˆ–ç”Ÿæˆçš„åŠ¨ä½œ)
        """
        if z is None:
            clip = self.max_action
            z = torch.randn((obs_feature.shape[0], self.latent_dim)).to(self.device).clamp(-clip, clip)
        
        a = F.relu(self.d1(torch.cat([obs_feature, z], 1)))
        a = F.relu(self.d2(a))
        a = F.relu(self.d3(a))
        a = self.d4(a)
        
        return a
```

**å…³é”®æ”¹è¿›**ï¼š
- âœ… ç¼–ç å™¨è¾“å…¥ï¼šèåˆç‰¹å¾ + åŠ¨ä½œï¼ˆè€ŒéçŠ¶æ€ + åŠ¨ä½œï¼‰
- âœ… è§£ç å™¨è¾“å…¥ï¼šèåˆç‰¹å¾ + éšå˜é‡ï¼ˆè€ŒéçŠ¶æ€ + éšå˜é‡ï¼‰
- âœ… å­¦ä¹ å¤šæ¨¡æ€è§‚å¯Ÿåˆ°åŠ¨ä½œçš„æ¡ä»¶åˆ†å¸ƒ

### 2.3 Criticç½‘ç»œä¿®æ”¹

**æ–‡ä»¶**: `algos/algos_vae_multimodal.py` (ç¬¬174-226è¡Œ)

```python
class Critic(nn.Module):
    """
    è¯„ä¼°ç½‘ç»œ - åŒ…å«åŒQå‡½æ•°å’ŒVå‡½æ•°
    
    Qç½‘ç»œ: (obs_feature + action) â†’ Qå€¼
    Vç½‘ç»œ: (obs_feature) â†’ Vå€¼
    """
    def __init__(self, obs_feature_dim, action_dim, device):
        super(Critic, self).__init__()
        hidden_size = (256, 256, 256)
        
        # Qå‡½æ•°1: (èåˆç‰¹å¾ + åŠ¨ä½œ) â†’ Qå€¼
        self.l1 = nn.Linear(obs_feature_dim + action_dim, hidden_size[0])
        self.l2 = nn.Linear(hidden_size[0], hidden_size[1])
        self.l3 = nn.Linear(hidden_size[1], hidden_size[2])
        self.l4 = nn.Linear(hidden_size[2], 1)
        
        # Qå‡½æ•°2: åŒQç»“æ„ç”¨äºè¿‡åº¦ä¼°è®¡ä¿®æ­£
        self.l5 = nn.Linear(obs_feature_dim + action_dim, hidden_size[0])
        self.l6 = nn.Linear(hidden_size[0], hidden_size[1])
        self.l7 = nn.Linear(hidden_size[1], hidden_size[2])
        self.l8 = nn.Linear(hidden_size[2], 1)
        
        # Vå‡½æ•°: èåˆç‰¹å¾ â†’ çŠ¶æ€ä»·å€¼
        self.v1 = nn.Linear(obs_feature_dim, hidden_size[0])
        self.v2 = nn.Linear(hidden_size[0], hidden_size[1])
        self.v3 = nn.Linear(hidden_size[1], hidden_size[2])
        self.v4 = nn.Linear(hidden_size[2], 1)
    
    def forward(self, obs_feature, action):
        """
        åŒQå‡½æ•°å‰å‘ä¼ æ’­
        è¾“å…¥:
            obs_feature: [batch, 256]
            action: [batch, 16]
        è¾“å‡º:
            q1, q2: ä¸¤ä¸ªQå€¼ä¼°è®¡
        """
        q1 = F.relu(self.l1(torch.cat([obs_feature, action], 1)))
        q1 = F.relu(self.l2(q1))
        q1 = F.relu(self.l3(q1))
        q1 = self.l4(q1)  # [batch, 1]
        
        q2 = F.relu(self.l5(torch.cat([obs_feature, action], 1)))
        q2 = F.relu(self.l6(q2))
        q2 = F.relu(self.l7(q2))
        q2 = self.l8(q2)  # [batch, 1]
        
        return q1, q2
    
    def q1(self, obs_feature, action):
        """å•ç‹¬è·å–Q1å€¼"""
        q1 = F.relu(self.l1(torch.cat([obs_feature, action], 1)))
        q1 = F.relu(self.l2(q1))
        q1 = F.relu(self.l3(q1))
        q1 = self.l4(q1)
        return q1
    
    def v(self, obs_feature):
        """Vå‡½æ•°è¯„ä¼°"""
        v = F.relu(self.v1(obs_feature))
        v = F.relu(self.v2(v))
        v = F.relu(self.v3(v))
        v = self.v4(v)  # [batch, 1]
        return v
```

**å…³é”®æ”¹è¿›**ï¼š
- âœ… Qç½‘ç»œè¾“å…¥ï¼šèåˆç‰¹å¾ + åŠ¨ä½œï¼ˆè€ŒéçŠ¶æ€ + åŠ¨ä½œï¼‰
- âœ… Vç½‘ç»œè¾“å…¥ï¼šèåˆç‰¹å¾ï¼ˆè€ŒéçŠ¶æ€ï¼‰
- âœ… ä¿ç•™åŒQç»“æ„ç”¨äºè¿‡åº¦ä¼°è®¡ä¿®æ­£
- âœ… æ”¯æŒç‹¬ç«‹è°ƒç”¨Q1æˆ–V

### 2.4 èåˆç‰¹å¾ç»´åº¦è§„èŒƒ

| ç»„ä»¶ | è¾“å…¥ç»´åº¦ | è¾“å‡ºç»´åº¦ | è¯´æ˜ |
|------|---------|---------|------|
| ResNet18Ã—3 | 3Ã—84Ã—84 | 128Ã—3=384 | ä¸‰ä¸ªç‹¬ç«‹ç¼–ç å™¨ |
| å…³èŠ‚FC | 16ç»´ | 128ç»´ | å…³èŠ‚ç‰¹å¾ |
| èåˆå±‚ | 512ç»´ | 256ç»´ | å¤šæ¨¡æ€èåˆ |
| Actor | 256ç»´ | 32ç»´ | éšç©ºé—´åŠ¨ä½œ |
| ActorVAEç¼–ç  | 256+16=272 | 32ç»´ | VAEéšå˜é‡ |
| ActorVAEè§£ç  | 256+32=288 | 16ç»´ | é‡æ„åŠ¨ä½œ |
| Critic.Q | 256+16=272 | 1ç»´ | Qå€¼ |
| Critic.V | 256ç»´ | 1ç»´ | çŠ¶æ€ä»·å€¼ |

---

## ğŸ’¾ ç¬¬ä¸‰å±‚é¢ï¼šæ•°æ®åŠ è½½ï¼ˆData Loadingï¼‰

### 3.1 MultimodalReplayBufferå®ç°

**æ–‡ä»¶**: `algos/utils_multimodal.py` (ç¬¬10-67è¡Œ)

```python
class MultimodalReplayBuffer(object):
    """
    å¤šæ¨¡æ€ç»éªŒå›æ”¾ç¼“å†²åŒº
    å­˜å‚¨ä¸‰è·¯å›¾åƒã€å…³èŠ‚æ•°æ®ã€åŠ¨ä½œã€å¥–åŠ±ç­‰
    """
    def __init__(self, action_dim, joint_dim=16, device='cpu', max_size=int(2e6)):
        self.max_size = max_size
        self.ptr = 0
        self.size = 0
        self.device = torch.device(device)
        
        self.action_dim = action_dim
        self.joint_dim = joint_dim
        
        # åˆå§‹åŒ–å­˜å‚¨ - æ”¯æŒå›¾åƒå’Œæ•°å€¼æ•°æ®
        self.storage = dict()
        self.storage['left_img'] = []          # åˆ—è¡¨å­˜å‚¨ï¼ˆå¯å˜é•¿ï¼‰
        self.storage['right_img'] = []
        self.storage['global_img'] = []
        self.storage['joint'] = np.zeros((max_size, joint_dim))  # æ•°ç»„å­˜å‚¨
        self.storage['action'] = np.zeros((max_size, action_dim))
        self.storage['next_left_img'] = []
        self.storage['next_right_img'] = []
        self.storage['next_global_img'] = []
        self.storage['next_joint'] = np.zeros((max_size, joint_dim))
        self.storage['reward'] = np.zeros((max_size, 1))
        self.storage['terminal'] = np.zeros((max_size, 1))
        
        # ç»Ÿè®¡ä¿¡æ¯ï¼ˆç”¨äºè§„èŒƒåŒ–ï¼‰
        self.action_mean = None
        self.action_std = None
        self.joint_mean = None
        self.joint_std = None
    
    def add(self, left_img, right_img, global_img, joint, action, 
            next_left_img, next_right_img, next_global_img, next_joint, 
            reward, terminal):
        """
        æ·»åŠ å•æ¡ç»éªŒ
        æ¥å—å¤šæ¨¡æ€æ•°æ®ï¼šä¸‰å¼ å›¾åƒ + å…³èŠ‚ + åŠ¨ä½œ + å¥–åŠ±
        """
        if self.ptr >= self.max_size:
            print(f"Warning: Replay buffer size exceeded {self.max_size}")
            return
        
        # å­˜å‚¨å›¾åƒï¼ˆä½œä¸ºåˆ—è¡¨å…ƒç´ ï¼‰
        self.storage['left_img'].append(left_img.copy())
        self.storage['right_img'].append(right_img.copy())
        self.storage['global_img'].append(global_img.copy())
        
        # å­˜å‚¨æ•°å€¼æ•°æ®ï¼ˆä½œä¸ºæ•°ç»„å…ƒç´ ï¼‰
        self.storage['joint'][self.ptr] = joint.copy()
        self.storage['action'][self.ptr] = action.copy()
        
        # å­˜å‚¨ä¸‹ä¸€çŠ¶æ€
        self.storage['next_left_img'].append(next_left_img.copy())
        self.storage['next_right_img'].append(next_right_img.copy())
        self.storage['next_global_img'].append(next_global_img.copy())
        self.storage['next_joint'][self.ptr] = next_joint.copy()
        
        # å­˜å‚¨å¥–åŠ±å’Œç»ˆæ­¢æ ‡å¿—
        self.storage['reward'][self.ptr] = reward
        self.storage['terminal'][self.ptr] = terminal
        
        self.ptr += 1
        self.size = min(self.ptr, self.max_size)
```

### 3.2 æ‰¹æ¬¡é‡‡æ ·å®ç°

**æ–‡ä»¶**: `algos/utils_multimodal.py` (ç¬¬69-103è¡Œ)

```python
def sample(self, batch_size):
    """
    é‡‡æ ·æ‰¹æ¬¡æ•°æ®
    è¿”å›å¤šæ¨¡æ€æ‰¹æ¬¡ï¼šå›¾åƒå¼ é‡ + æ•°å€¼å¼ é‡
    """
    ind = np.random.randint(0, self.size, size=batch_size)
    
    # 1. æ”¶é›†å›¾åƒæ•°æ®ï¼ˆä»åˆ—è¡¨è½¬ä¸ºnumpyæ•°ç»„ï¼‰
    left_imgs = np.array([self.storage['left_img'][i] for i in ind], dtype=np.float32)
    right_imgs = np.array([self.storage['right_img'][i] for i in ind], dtype=np.float32)
    global_imgs = np.array([self.storage['global_img'][i] for i in ind], dtype=np.float32)
    next_left_imgs = np.array([self.storage['next_left_img'][i] for i in ind], dtype=np.float32)
    next_right_imgs = np.array([self.storage['next_right_img'][i] for i in ind], dtype=np.float32)
    next_global_imgs = np.array([self.storage['next_global_img'][i] for i in ind], dtype=np.float32)
    
    # 2. è½¬æ¢ä¸ºPyTorchå¼ é‡å¹¶å½’ä¸€åŒ–
    left_imgs = torch.FloatTensor(left_imgs).to(self.device) / 255.0
    right_imgs = torch.FloatTensor(right_imgs).to(self.device) / 255.0
    global_imgs = torch.FloatTensor(global_imgs).to(self.device) / 255.0
    next_left_imgs = torch.FloatTensor(next_left_imgs).to(self.device) / 255.0
    next_right_imgs = torch.FloatTensor(next_right_imgs).to(self.device) / 255.0
    next_global_imgs = torch.FloatTensor(next_global_imgs).to(self.device) / 255.0
    
    # 3. æ”¶é›†æ•°å€¼æ•°æ®
    joints = torch.FloatTensor(self.storage['joint'][ind]).to(self.device)
    next_joints = torch.FloatTensor(self.storage['next_joint'][ind]).to(self.device)
    actions = torch.FloatTensor(self.storage['action'][ind]).to(self.device)
    rewards = torch.FloatTensor(self.storage['reward'][ind]).to(self.device)
    terminals = torch.FloatTensor(self.storage['terminal'][ind]).to(self.device)
    
    # 4. è§„èŒƒåŒ–
    joints = self.normalize_joint(joints)
    next_joints = self.normalize_joint(next_joints)
    actions = self.normalize_action(actions)
    
    not_done = 1.0 - terminals
    
    # è¿”å›å®Œæ•´çš„å¤šæ¨¡æ€æ‰¹æ¬¡
    return (left_imgs, right_imgs, global_imgs, joints, actions, 
            next_left_imgs, next_right_imgs, next_global_imgs, next_joints, 
            rewards, not_done)
```

### 3.3 HDF5æ–‡ä»¶åŠ è½½å®ç°

**æ–‡ä»¶**: `algos/utils_multimodal.py` (ç¬¬123-181è¡Œ)

```python
def load_from_hdf5(self, hdf5_path, num_traj=None):
    """
    ä»HDF5æ–‡ä»¶åŠ è½½æ•°æ®
    
    æœŸæœ›çš„æ–‡ä»¶æ ¼å¼:
    {
        'observations': {
            'left_image': [N, H, W, 3],
            'right_image': [N, H, W, 3],
            'global_image': [N, H, W, 3],
            'joint': [N, 16]
        },
        'actions': [N, 16],
        'rewards': [N],
        'terminals': [N]
    }
    """
    print(f"Loading data from {hdf5_path}...")
    
    with h5py.File(hdf5_path, 'r') as f:
        # æ˜¾ç¤ºHDF5æ–‡ä»¶ç»“æ„ï¼ˆè°ƒè¯•ç”¨ï¼‰
        print("HDF5 structure:")
        def print_structure(name, obj):
            print(f"  {name}: shape={obj.shape if hasattr(obj, 'shape') else 'N/A'}")
        f.visititems(print_structure)
        
        # æå–æ•°æ®ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
        if 'observations' in f:
            obs = f['observations']
            left_images = obs['left_image'][:] if 'left_image' in obs else obs['left_wrist_image'][:]
            right_images = obs['right_image'][:] if 'right_image' in obs else obs['right_wrist_image'][:]
            global_images = obs['global_image'][:]
            joints = obs['joint'][:]
        else:
            # æ›¿ä»£æ ¼å¼
            left_images = f['left_image'][:]
            right_images = f['right_image'][:]
            global_images = f['global_image'][:]
            joints = f['joint'][:]
        
        actions = f['actions'][:]
        rewards = f['rewards'][:]
        terminals = f['terminals'][:]
    
    # æ ¼å¼è½¬æ¢ï¼šNHWC â†’ NCHWï¼ˆå¦‚æœéœ€è¦ï¼‰
    if left_images.ndim == 4:
        if left_images.shape[-1] == 3:  # NHWCæ ¼å¼
            left_images = np.transpose(left_images, (0, 3, 1, 2))
            right_images = np.transpose(right_images, (0, 3, 1, 2))
            global_images = np.transpose(global_images, (0, 3, 1, 2))
    
    # å¤„ç†è½¨è¿¹æ•°æ®
    n_samples = len(actions)
    if num_traj is not None:
        n_samples = min(n_samples, num_traj)
    
    print(f"Loading {n_samples} transitions...")
    for i in tqdm(range(n_samples - 1)):
        self.add(
            left_images[i], right_images[i], global_images[i], joints[i],
            actions[i],
            left_images[i + 1], right_images[i + 1], global_images[i + 1], joints[i + 1],
            rewards[i], terminals[i]
        )
    
    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯ç”¨äºè§„èŒƒåŒ–
    self.compute_statistics()
    print(f"Loaded {self.size} transitions")
```

### 3.4 è§„èŒƒåŒ–å’Œåè§„èŒƒåŒ–

**æ–‡ä»¶**: `algos/utils_multimodal.py` (ç¬¬105-121è¡Œ)

```python
def normalize_joint(self, joint):
    """è§„èŒƒåŒ–å…³èŠ‚æ•°æ®"""
    if self.joint_mean is not None:
        return (joint - self.joint_mean) / (self.joint_std + 1e-6)
    return joint

def unnormalize_joint(self, joint):
    """åè§„èŒƒåŒ–å…³èŠ‚æ•°æ®"""
    if self.joint_mean is not None:
        return joint * (self.joint_std + 1e-6) + self.joint_mean
    return joint

def normalize_action(self, action):
    """è§„èŒƒåŒ–åŠ¨ä½œ"""
    if self.action_mean is not None:
        return (action - self.action_mean) / (self.action_std + 1e-6)
    return action

def unnormalize_action(self, action):
    """åè§„èŒƒåŒ–åŠ¨ä½œ"""
    if self.action_mean is not None:
        return action * (self.action_std + 1e-6) + self.action_mean
    return action
```

### 3.5 ç»Ÿè®¡ä¿¡æ¯è®¡ç®—

**æ–‡ä»¶**: `algos/utils_multimodal.py` (ç¬¬183-205è¡Œ)

```python
def compute_statistics(self):
    """è®¡ç®—å…³èŠ‚å’ŒåŠ¨ä½œçš„ç»Ÿè®¡ä¿¡æ¯"""
    print("Computing statistics...")
    self.action_mean = np.mean(self.storage['action'][:self.size], axis=0)
    self.action_std = np.std(self.storage['action'][:self.size], axis=0)
    self.joint_mean = np.mean(self.storage['joint'][:self.size], axis=0)
    self.joint_std = np.std(self.storage['joint'][:self.size], axis=0)
    
    print(f"Action - mean: {self.action_mean}, std: {self.action_std}")
    print(f"Joint - mean: {self.joint_mean}, std: {self.joint_std}")
```

### 3.6 æ•°æ®æµå‘å›¾

```
HDF5æ–‡ä»¶ (.hdf5)
     â”‚
     â””â”€â†’ h5py.File() è¯»å–
          â”‚
     â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚         â”‚        â”‚        â”‚        â”‚
  left_img  right_img  global  joints  actions
     â”‚         â”‚        â”‚        â”‚        â”‚
     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚         â”‚        â”‚
     è½¬ä¸ºåˆ—è¡¨     è½¬ä¸ºå¼ é‡    è½¬ä¸ºå¼ é‡
     (NHWCâ†’NCHW)  (å½’ä¸€åŒ–)   (è§„èŒƒåŒ–)
          â”‚         â”‚        â”‚
          â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
               â”‚ æ‰¹æ¬¡é‡‡æ · â”‚
               â”‚  (Ã—batch_size)
               â”‚
          â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ å¤šæ¨¡æ€æ‰¹æ¬¡å¼ é‡ tuple â”‚
          â”‚ (imgÃ—3 + joints+...)  â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š ä¿®æ”¹å¯¹æ¯”è¡¨

### åŸå§‹LAPO vs å¤šæ¨¡æ€LAPO

| ç»´åº¦ | åŸå§‹LAPO | å¤šæ¨¡æ€LAPO | æ”¹è¿› |
|------|---------|----------|------|
| **è§‚å¯Ÿè¾“å…¥** | ä½ç»´å‘é‡ | å¤šæ¨¡æ€ | âœ… å¢åŠ å›¾åƒ+å…³èŠ‚ |
| **ç‰¹å¾æå–** | æ—  | ResNet18Ã—3 | âœ… è§†è§‰ç¼–ç  |
| **ç‰¹å¾èåˆ** | æ—  | ImageJointEncoder | âœ… å¤šæ¨¡æ€èåˆ |
| **Actorè¾“å…¥** | çŠ¶æ€å‘é‡ | èåˆç‰¹å¾ | âœ… ä»256ç»´èåˆç‰¹å¾ |
| **ActorVAEè¾“å…¥** | (çŠ¶æ€,åŠ¨ä½œ) | (èåˆç‰¹å¾,åŠ¨ä½œ) | âœ… å¤šæ¨¡æ€æ¡ä»¶ |
| **Criticè¾“å…¥** | (çŠ¶æ€,åŠ¨ä½œ) | (èåˆç‰¹å¾,åŠ¨ä½œ) | âœ… å¤šæ¨¡æ€è¯„ä¼° |
| **æ•°æ®åŠ è½½** | NumPy | HDF5 | âœ… å¤§è§„æ¨¡æ•°æ®æ”¯æŒ |
| **å›¾åƒå¤„ç†** | æ—  | RGBå›¾åƒ+æ ¼å¼è½¬æ¢ | âœ… æ”¯æŒ9é€šé“è¾“å…¥ |
| **è§„èŒƒåŒ–** | ä»…çŠ¶æ€/åŠ¨ä½œ | çŠ¶æ€/åŠ¨ä½œ/å…³èŠ‚/å›¾åƒ | âœ… å®Œæ•´è§„èŒƒåŒ– |

---

## ğŸ“ å…³é”®æ¦‚å¿µè¯´æ˜

### èåˆç‰¹å¾ï¼ˆFused Observation Featureï¼‰
- ç»¼åˆäº†æ‰€æœ‰æ¨¡æ€çš„ä¿¡æ¯
- ç»´åº¦å›ºå®šä¸º256ç»´
- è¾“å…¥åˆ°æ‰€æœ‰åç»­ç½‘ç»œï¼ˆActor, VAE, Criticï¼‰
- æ›¿ä»£äº†åŸå§‹çš„çŠ¶æ€å‘é‡

### å¤šæ¨¡æ€CVAE
- æ¡ä»¶ï¼šèåˆè§‚å¯Ÿç‰¹å¾ï¼ˆè€ŒéåŸå§‹è§‚å¯Ÿï¼‰
- è¾“å…¥ï¼šåŠ¨ä½œï¼ˆå­¦ä¹ åŠ¨ä½œåˆ†å¸ƒï¼‰
- è¾“å‡ºï¼šéšå˜é‡å’Œé‡æ„åŠ¨ä½œ
- å­¦ä¹  $p(a|obs_{fused})$

### åŒQå­¦ä¹ 
- Q1å’ŒQ2ç‹¬ç«‹å‚æ•°åŒ–
- å–è¾ƒå°å€¼ç”¨äºç›®æ ‡è®¡ç®—
- å‡å°‘è¿‡åº¦ä¼°è®¡åå·®
- æé«˜ç¦»çº¿å¼ºåŒ–å­¦ä¹ ç¨³å®šæ€§

---

## âœ… æ€»ç»“

### ç¬¬ä¸€å±‚é¢å®Œæˆé¡¹
- âœ… ResNet18å›¾åƒç¼–ç å™¨
- âœ… ä¸‰ä¸ªç‹¬ç«‹çš„å›¾åƒç‰¹å¾æå–è·¯å¾„
- âœ… å…³èŠ‚ç‰¹å¾ç½‘ç»œ
- âœ… èåˆå±‚ï¼ˆ512â†’256ï¼‰
- âœ… 9é€šé“ï¼ˆ3Ã—RGBï¼‰è¾“å…¥æ”¯æŒ

### ç¬¬äºŒå±‚é¢å®Œæˆé¡¹
- âœ… Actoræ¥å—èåˆç‰¹å¾è¾“å…¥
- âœ… ActorVAEæ¥å—èåˆç‰¹å¾+åŠ¨ä½œè¾“å…¥
- âœ… Critic Qç½‘ç»œæ¥å—èåˆç‰¹å¾+åŠ¨ä½œ
- âœ… Critic Vç½‘ç»œæ¥å—èåˆç‰¹å¾
- âœ… ä¿ç•™åŸå§‹LAPOçš„æ ¸å¿ƒé€»è¾‘

### ç¬¬ä¸‰å±‚é¢å®Œæˆé¡¹
- âœ… MultimodalReplayBufferæ”¯æŒå›¾åƒå­˜å‚¨
- âœ… HDF5æ–‡ä»¶åŠ è½½
- âœ… NHWCâ†”NCHWæ ¼å¼è½¬æ¢
- âœ… å›¾åƒè§„èŒƒåŒ–ï¼ˆ/255.0ï¼‰
- âœ… æ•°æ®ç»Ÿè®¡å’Œè§„èŒƒåŒ–
- âœ… æ‰¹æ¬¡é‡‡æ ·

---

## ğŸš€ ä½¿ç”¨ç¤ºä¾‹

```python
# 1. åˆ›å»ºå¤šæ¨¡æ€ç¼“å†²åŒº
buffer = MultimodalReplayBuffer(action_dim=16, joint_dim=16, device='cuda')

# 2. åŠ è½½HDF5æ•°æ®
buffer.load_from_hdf5('robot_data.hdf5')

# 3. åˆ›å»ºç­–ç•¥
policy = MultimodalLatent(
    action_dim=16, latent_dim=32, max_action=1.0, ...,
    replay_buffer=buffer, device='cuda'
)

# 4. è®­ç»ƒ
policy.train(iterations=1000, batch_size=64)

# 5. æ¨ç†
action = policy.select_action(left_img, right_img, global_img, joint)
```

å®Œæ•´ä»£ç å·²å®ç°å¹¶å¯ç›´æ¥ä½¿ç”¨ï¼
