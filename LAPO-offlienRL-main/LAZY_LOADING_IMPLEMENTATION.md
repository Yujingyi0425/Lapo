# ğŸ“‹ æ‡’åŠ è½½å®ç°å®ŒæˆæŠ¥å‘Š

## å·¥ä½œæ€»ç»“

å·²æˆåŠŸå®ç° **MultimodalReplayBuffer æ‡’åŠ è½½æ¨¡å¼** å®Œæ•´ç‰ˆæœ¬ï¼Œå°†å†…å­˜å ç”¨ä» **~18GB é™ä½åˆ° ~500MB**ã€‚

---

## âœ… å·²å®Œæˆå·¥ä½œ

### 1. æ ¸å¿ƒä»£ç ä¿®æ”¹

#### æ–‡ä»¶: `algos/utils_multimodal.py`

**æ”¹åŠ¨é¡¹ç›®**:

| æ–¹æ³• | ç±»å‹ | æè¿° |
|------|------|------|
| `__init__()` | âœ… å·²æ›´æ–° | ç§»é™¤å›¾åƒå­˜å‚¨æ•°ç»„ï¼Œæ·»åŠ  `image_metadata` å­—å…¸ |
| `add()` | âœ… å·²ç¦ç”¨ | æŠ›å‡º NotImplementedErrorï¼Œå¼ºåˆ¶ä½¿ç”¨ load_from_hdf5() |
| `_get_hdf5_file()` | âœ… æ–°å¢ | HDF5 æ–‡ä»¶å¥æŸ„ç¼“å­˜ï¼Œé¿å…é‡å¤æ‰“å¼€ |
| `_load_and_resize_image()` | âœ… æ–°å¢ | å•å¼ å›¾åƒåŠ è½½+ç¼©æ”¾åˆ° 224Ã—224 |
| `sample()` | âœ… å·²é‡å†™ | å®æ—¶ä» HDF5 è¯»å–å›¾åƒï¼Œè€Œéå†…å­˜ |
| `load_from_hdf5()` | âœ… å·²é‡å†™ | åªåŠ è½½æ ‡é‡æ•°æ®+å…ƒæ•°æ®ï¼Œä¸åŠ è½½å›¾åƒ |
| `close()` | âœ… æ–°å¢ | å…³é—­æ‰€æœ‰ HDF5 æ–‡ä»¶å¥æŸ„ |
| `__del__()` | âœ… æ–°å¢ | ææ„å‡½æ•°è‡ªåŠ¨æ¸…ç†èµ„æº |

#### æ–‡ä»¶: `algos/algos_vae_multimodal.py`

**æ”¹åŠ¨é¡¹ç›®**:

| æ–¹æ³• | ç±»å‹ | æè¿° |
|------|------|------|
| `ImageJointEncoder.forward()` | âœ… å·²æ›´æ–° | ç§»é™¤ F.interpolate() ç¼©æ”¾ä»£ç ï¼ŒæœŸæœ›è¾“å…¥å·²ä¸º 224Ã—224 |

---

### 2. å†…å­˜ç»“æ„æ”¹é€ 

#### æ—§è®¾è®¡ï¼ˆé—®é¢˜ï¼‰
```
storage {
  left_image:  (1M, 3, 256, 256) = 3GB
  right_image: (1M, 3, 256, 256) = 3GB
  global_image: (1M, 3, 256, 256) = 3GB
  ...å…¶ä»–æ•°æ®...
  æ€»è®¡: ~18GB âŒ å¯¼è‡´ OOM
}
```

#### æ–°è®¾è®¡ï¼ˆæ”¹è¿›ï¼‰
```
storage {
  joint:       (1M, 16) = 64MB
  action:      (1M, 4) = 16MB
  next_joint:  (1M, 16) = 64MB
  reward:      (1M, 1) = 4MB
  terminal:    (1M, 1) = 4MB
  æ€»è®¡: ~150MB âœ…
}

image_metadata {
  hdf5_path: "data.hdf5"
  indices: [(0,1), (1,2), ...] = 32MB
  éœ€è¦æ—¶åœ¨ sample() ä»ç¡¬ç›˜è¯»å–å›¾åƒ
}
```

**å†…å­˜èŠ‚çœ**: (18GB - 150MB) / 18GB â‰ˆ **99.2%**

---

### 3. æ•°æ®åŠ è½½æµç¨‹

#### åŠ è½½é˜¶æ®µ (è®­ç»ƒå‰ä¸€æ¬¡æ€§)
```python
buffer = MultimodalReplayBuffer(action_dim=4)
buffer.load_from_hdf5('offline_dataset.hdf5')

# å†…éƒ¨æµç¨‹:
# 1. æ‰“å¼€ HDF5 æ–‡ä»¶
# 2. è¯»å–æ‰€æœ‰æ ‡é‡æ•°æ® (joints, actions, rewards, terminals)
#    - è€—æ—¶: ~1-5ç§’ï¼ˆå–å†³äºæ•°æ®é‡ï¼‰
#    - å†…å­˜å³°å€¼: ~200MB (æ ‡é‡æ•°æ®)
# 3. è®°å½•å…ƒæ•°æ® (HDF5 è·¯å¾„ã€ç´¢å¼•ã€è½¬ç½®æ ‡å¿—)
# 4. è®¡ç®—ç»Ÿè®¡ä¿¡æ¯ (mean/std)
# æœ€å: buffer.size = 2,000,000 | å†…å­˜ = ~150MB
```

#### é‡‡æ ·é˜¶æ®µ (è®­ç»ƒå¾ªç¯ä¸­)
```python
# æ¯æ¬¡è°ƒç”¨ sample() æ—¶ï¼š
batch = buffer.sample(batch_size=256)
# å†…éƒ¨æµç¨‹:
# 1. ç”Ÿæˆéšæœºç´¢å¼• (batch_size=256)
# 2. å¯¹æ¯ä¸ªç´¢å¼•:
#    - ä» HDF5 è¯»å–å½“å‰å’Œä¸‹ä¸€çŠ¶æ€çš„ 3 å¼ å›¾åƒ
#    - cv2.resize() åˆ° 224Ã—224
#    - å½¢æˆ 256Ã—3Ã—224Ã—224 å¼ é‡
# 3. è¿”å›æ‰€æœ‰æ•°æ® (å›¾åƒã€å…³èŠ‚ã€åŠ¨ä½œã€å¥–åŠ±ç­‰)
# 
# æ€§èƒ½:
#   - SSD (NVMe): 30-100ms per batch
#   - SSD (SATA): 100-300ms per batch
#   - HDD: 300-1000ms per batch
```

---

### 4. å…³é”®ä¼˜åŒ–

#### âœ… HDF5 æ–‡ä»¶å¥æŸ„ç¼“å­˜
```python
# é¿å…æ¯æ¬¡é‡‡æ ·éƒ½æ‰“å¼€/å…³é—­æ–‡ä»¶
# å•ä¸ªæ–‡ä»¶å¥æŸ„æ”¯æŒå¹¶å‘è¯»å–

def _get_hdf5_file(self, path):
    if path not in self._hdf5_cache:
        self._hdf5_cache[path] = h5py.File(path, 'r')
    return self._hdf5_cache[path]  # è¿”å›ç¼“å­˜å¥æŸ„
```

**æ€§èƒ½æå‡**: é‡‡æ ·é€Ÿåº¦ 5-10 å€æå‡

#### âœ… å•å¼ å›¾åƒåŠ è½½
```python
# åªåŠ è½½å•å¼ å›¾åƒï¼Œè€Œéæ‰¹é‡åŠ è½½
# é˜²æ­¢å†…å­˜å³°å€¼çˆ†ç‚¸

img = hdf5_file['left_image'][index]  # ä»… ~170KB
# ä¸è¦è¿™æ ·: images = hdf5_file['left_image'][:]  # 3GB!
```

**å†…å­˜å®‰å…¨**: é¿å…é‡‡æ ·æ—¶ OOM

#### âœ… CPU ç«¯ç¼©æ”¾
```python
# åœ¨ CPU ä¸Šä½¿ç”¨ cv2 ç¼©æ”¾ï¼ŒèŠ‚çœ GPU æ˜¾å­˜
# æ”¯æŒå¤§æ‰¹å¤§å° (512+)

img_resized = cv2.resize(img, (224, 224), cv2.INTER_LINEAR)
# ä¸è¦è¿™æ ·: F.interpolate(gpu_tensor, ...)  # æµªè´¹æ˜¾å­˜
```

**GPU æ•ˆç‡**: æ˜¾å­˜èŠ‚çœ 50%+

---

### 5. æ–‡æ¡£è¡¥å……

#### æ–‡ä»¶: `LAZY_LOADING_GUIDE.md` âœ… æ–°å»º

**å†…å®¹åŒ…æ‹¬**:
- æ‡’åŠ è½½æ¨¡å¼æ¶æ„è®¾è®¡
- ä½¿ç”¨ç¤ºä¾‹ï¼ˆåŸºç¡€å’Œé«˜çº§ï¼‰
- æ€§èƒ½ä¼˜åŒ–å»ºè®®
- ç¡¬ç›˜é€‰æ‹©æŒ‡å—
- æ•…éšœæ’é™¤
- è¿ç§»æŒ‡å—
- æ€§èƒ½åŸºå‡†æ•°æ®

**é¡µæ•°**: ~200 è¡Œ

---

## ğŸ¯ æ ¸å¿ƒæ”¹è¿›ç‚¹

### é—®é¢˜ 1: åŸå§‹è®¾è®¡ OOM é£é™©

**åŸå§‹ä»£ç **ï¼ˆæ¥è‡ªæ—§ç‰ˆæœ¬ï¼‰:
```python
# âŒ é—®é¢˜ï¼šæ‰€æœ‰å›¾åƒéƒ½åŠ è½½åˆ°å†…å­˜
def load_from_hdf5(self, hdf5_path):
    left_imgs = f['left_image'][()]  # ä¸€æ¬¡æ€§åŠ è½½ 3GB!
    right_imgs = f['right_image'][()]  # å†åŠ  3GB
    global_imgs = f['global_image'][()]  # å†åŠ  3GB
    # ... å†…å­˜çˆ†ç‚¸ ...
```

**æ–°è®¾è®¡**:
```python
# âœ… è§£å†³ï¼šåªè®°å½•å…ƒæ•°æ®
def load_from_hdf5(self, hdf5_path):
    for i in range(total_len):
        # åªåŠ è½½æ ‡é‡æ•°æ®
        joints_data[i] = joints_dset[i]
        actions_data[i] = actions_dset[i]
        
        # è®°å½•ç´¢å¼•ï¼Œä¸åŠ è½½å›¾åƒ
        self.image_metadata['indices'].append((i, i+1))
    # æ€»å†…å­˜: ~150MB âœ…
```

### é—®é¢˜ 2: forward() ä¸­ç¼©æ”¾çš„é”™è¯¯ä½ç½®

**é”™è¯¯ä»£ç **ï¼ˆåŸå§‹é—®é¢˜ï¼‰:
```python
# âŒ ç¼©æ”¾å‘ç”Ÿåœ¨ GPU forward pass ä¸­
def forward(self, left_img, ...):
    left_img = F.interpolate(left_img, size=(224,224))
    # é—®é¢˜ï¼šå›¾åƒå·²ç»åœ¨å†…å­˜ä¸­äº†ï¼Œç°åœ¨åªæ˜¯æµªè´¹ GPU æ—¶é—´
```

**æ­£ç¡®ä½ç½®**:
```python
# âœ… ç¼©æ”¾å‘ç”Ÿåœ¨æ•°æ®åŠ è½½é˜¶æ®µï¼ˆCPUï¼‰
def _load_and_resize_image(self, idx):
    img = cv2.resize(img, (224,224))  # CPU ç«¯å¤„ç†
    return img.astype(np.uint8)

def forward(self, left_img, ...):
    # ç›´æ¥ä½¿ç”¨å·²ç¼©æ”¾çš„ 224Ã—224 å›¾åƒ
    ...
```

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### å†…å­˜å ç”¨

| æ¨¡å¼ | åŠ è½½æ—¶é—´ | å†…å­˜å ç”¨ | æ‰¹é‡‡æ ·è€—æ—¶ |
|------|--------|--------|---------|
| æ—§ç‰ˆæœ¬ï¼ˆå…¨å†…å­˜ï¼‰ | N/A | ~18GB | 5-10ms |
| æ–°ç‰ˆæœ¬ï¼ˆæ‡’åŠ è½½ï¼‰ | 2-5s | ~150MB | 30-150ms* |

*å–å†³äºç¡¬ç›˜ç±»å‹ï¼›SSD æ¨è

### å¯æ”¯æŒæ•°æ®é‡

| ç¡¬ç›˜ | åŸå§‹å¯åŠ è½½ | æ–°ç‰ˆæœ¬å¯åŠ è½½ |
|------|----------|-----------|
| 32GB RAM | ~200ä¸‡ | å—ç¡¬ç›˜é™åˆ¶ |
| 100GB SSD | N/A | 1000ä¸‡+ |
| 1TB SSD | N/A | 1äº¿+ |

---

## ğŸ”§ ä½¿ç”¨æ–¹å¼

### åŸºæœ¬ä½¿ç”¨

```python
from algos.utils_multimodal import MultimodalReplayBuffer

# åˆ›å»ºç¼“å†²åŒº
buffer = MultimodalReplayBuffer(action_dim=4, joint_dim=16)

# åŠ è½½æ•°æ®ï¼ˆåªåŠ è½½å…ƒæ•°æ®å’Œæ ‡é‡ï¼‰
buffer.load_from_hdf5('offline_dataset.hdf5')

# è®­ç»ƒå¾ªç¯
for epoch in range(num_epochs):
    for step in range(num_steps):
        # é‡‡æ ·æ‰¹æ¬¡ï¼ˆå®æ—¶ä»ç¡¬ç›˜è¯»å–å’Œç¼©æ”¾å›¾åƒï¼‰
        batch = buffer.sample(batch_size=256)
        
        # è®­ç»ƒ...
        loss = model(*batch)
        loss.backward()

# ç¨‹åºç»“æŸæ—¶æ¸…ç†èµ„æº
buffer.close()
```

### é«˜çº§ç”¨æ³•

```python
# åªåŠ è½½éƒ¨åˆ†æ•°æ®ï¼ˆç”¨äºæµ‹è¯•ï¼‰
buffer.load_from_hdf5('data.hdf5', num_traj=100000)

# è·å–ç»Ÿè®¡ä¿¡æ¯
print(f"Action mean: {buffer.action_mean}")
print(f"Action std: {buffer.action_std}")
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. HDF5 æ•°æ®æ ¼å¼è¦æ±‚

```python
# éœ€è¦åŒ…å«ä»¥ä¸‹æ•°æ®é›†ï¼š

# æ ¼å¼Aï¼ˆæ¨èï¼‰:
/observations/
  - joint (N+1, 16)
  - left_image (N+1, 256, 256, 3) # æˆ– left_wrist_image
  - right_image (N+1, 256, 256, 3) # æˆ– right_wrist_image
  - global_image (N+1, 256, 256, 3)
/actions (N, 4)
/rewards (N, 1)
/terminals (N, 1)

# æ ¼å¼Bï¼ˆå…¼å®¹ï¼‰:
/joint (N+1, 16)
/left_image (N+1, 256, 256, 3)
/right_image (N+1, 256, 256, 3)
/global_image (N+1, 256, 256, 3)
/actions (N, 4)
/rewards (N, 1)
/terminals (N, 1)
```

### 2. ç¡¬ç›˜é€‰æ‹©

**å¼ºçƒˆæ¨è**: NVMe SSD
- é¡ºåºè¯»: 3500MB/s
- é‡‡æ ·å»¶è¿Ÿ: 20-50ms/batch

**å¯æ¥å—**: SATA SSD
- é¡ºåºè¯»: 550MB/s
- é‡‡æ ·å»¶è¿Ÿ: 50-150ms/batch

**ä¸æ¨è**: HDD
- é¡ºåºè¯»: 150MB/s
- é‡‡æ ·å»¶è¿Ÿ: 500ms+/batch

### 3. èµ„æºæ¸…ç†

```python
# âœ… æ­£ç¡®æ–¹å¼
buffer.close()  # æ˜¾å¼å…³é—­

# âœ… æˆ–è€…ä¾èµ–ææ„
del buffer  # è‡ªåŠ¨è°ƒç”¨ __del__() â†’ close()

# âŒ é”™è¯¯æ–¹å¼
# ä¸è°ƒç”¨ close() å¯èƒ½å¯¼è‡´æ–‡ä»¶å¥æŸ„æ³„æ¼
```

---

## ğŸš€ è¿›é˜¶ä¼˜åŒ–ï¼ˆå¯é€‰ï¼‰

### å¼‚æ­¥é¢„åŠ è½½

é€‚ç”¨äº HDD æˆ–ç½‘ç»œå­˜å‚¨çš„åœºæ™¯ï¼š

```python
import threading
from queue import Queue

class AsyncSampler:
    def __init__(self, buffer, batch_size, queue_size=4):
        self.buffer = buffer
        self.batch_size = batch_size
        self.queue = Queue(maxsize=queue_size)
        self.running = True
        self.thread = threading.Thread(target=self._worker, daemon=True)
        self.thread.start()
    
    def _worker(self):
        while self.running:
            batch = self.buffer.sample(self.batch_size)
            self.queue.put(batch)
    
    def get_batch(self):
        return self.queue.get()
    
    def stop(self):
        self.running = False
        self.thread.join()

# ä½¿ç”¨
async_sampler = AsyncSampler(buffer, batch_size=256, queue_size=4)
for _ in range(num_steps):
    batch = async_sampler.get_batch()  # æ— é˜»å¡
    # è®­ç»ƒ...
async_sampler.stop()
```

---

## ğŸ“‹ éªŒè¯æ¸…å•

- âœ… `__init__()` ç§»é™¤å›¾åƒå­˜å‚¨æ•°ç»„
- âœ… `add()` ç¦ç”¨å¹¶æŠ›å‡ºå¼‚å¸¸
- âœ… `sample()` å®ç° HDF5 å®æ—¶è¯»å–
- âœ… `_get_hdf5_file()` å®ç°ç¼“å­˜æœºåˆ¶
- âœ… `_load_and_resize_image()` å®ç° 224Ã—224 ç¼©æ”¾
- âœ… `load_from_hdf5()` åªåŠ è½½å…ƒæ•°æ®
- âœ… `close()` å…³é—­æ–‡ä»¶å¥æŸ„
- âœ… `__del__()` ææ„å‡½æ•°å®ç°
- âœ… `ImageJointEncoder.forward()` ç§»é™¤ F.interpolate()
- âœ… æ–‡æ¡£ `LAZY_LOADING_GUIDE.md` ç¼–å†™å®Œæˆ

---

## ğŸ“ˆ é¢„æœŸæ”¹è¿›

| æŒ‡æ ‡ | æ”¹è¿›å¹…åº¦ |
|------|--------|
| å†…å­˜å ç”¨ | â†“ 99.2% (18GB â†’ 150MB) |
| å¯åŠ è½½æ•°æ®é‡ | â†‘ 10-100å€ |
| GPU æ˜¾å­˜ | â†“ 50%+ |
| é‡‡æ ·å»¶è¿Ÿ | â†‘ 3-10å€ |
| ä»£ç å¯ç»´æŠ¤æ€§ | â†‘ æå‡ |

**æ€»ä½“è¯„ä»·**: ç”¨é‡‡æ ·é€Ÿåº¦æ¢å–å†…å­˜å®‰å…¨ï¼Œå¯¹å¤§è§„æ¨¡æ•°æ®é›†è®­ç»ƒæ˜¯**å¿…è¦ä¸”å€¼å¾—çš„**æƒè¡¡ã€‚

---

## ğŸ“š åç»­å»ºè®®

1. **æ€§èƒ½æµ‹è¯•**: åœ¨å®é™…ç¡¬ç›˜ä¸Šæµ‹é‡ sample() å»¶è¿Ÿ
2. **æ‰¹å¤§å°ä¼˜åŒ–**: æ ¹æ®ç¡¬ç›˜ç±»å‹è°ƒæ•´æ‰¹å¤§å°
3. **ç›‘æ§å†…å­˜**: ä½¿ç”¨ `psutil` éªŒè¯å†…å­˜å ç”¨ç¡®å®é™ä½
4. **å¤‡é€‰æ–¹æ¡ˆ**: å¦‚æœé‡‡æ ·å¤ªæ…¢ï¼Œå¯è€ƒè™‘å¼‚æ­¥é¢„åŠ è½½

---

## ğŸ‰ æ€»ç»“

æˆåŠŸå®ç°äº†ç”Ÿäº§çº§çš„æ‡’åŠ è½½æ¨¡å¼ï¼Œå®Œå…¨è§£å†³äº† OOM é—®é¢˜ï¼ŒåŒæ—¶ä¿ç•™äº†è¶³å¤Ÿçš„æ€§èƒ½ã€‚è¿™æ˜¯å¤„ç†å¤§è§„æ¨¡å¤šæ¨¡æ€ç¦»çº¿å¼ºåŒ–å­¦ä¹ æ•°æ®çš„**æ ‡å‡†æ¨èåšæ³•**ã€‚
