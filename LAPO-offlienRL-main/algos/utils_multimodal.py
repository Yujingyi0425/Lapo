import numpy as np
import torch
import h5py
import cv2
from tqdm import tqdm

class MultimodalReplayBuffer(object):
    """
    å¤šæ¨¡æ€ç»éªŒå›æ”¾ç¼“å†²åŒº - æœ€ç»ˆä¼˜åŒ–ç‰ˆ
    
    ç‰¹ç‚¹ï¼š
    1. æ‡’åŠ è½½ (Lazy Loading): å›¾åƒä¸å å†…å­˜ï¼Œé‡‡æ ·æ—¶å®æ—¶è¯»å–
    2. å‘é‡åŒ–åŠ è½½: å¯åŠ¨é€Ÿåº¦å¿«
    3. è‡ªåŠ¨ Resize: å›¾åƒå¼ºåˆ¶è½¬æ¢ä¸º 224x224 (CHW)
    4. æ— å½’ä¸€åŒ–: å‡è®¾è¾“å…¥æ•°æ®å·²å½’ä¸€åŒ–ï¼Œç›´æ¥è¾“å‡ºåŸå€¼
    """
    def __init__(self, action_dim, joint_dim=16, device='cpu', max_size=int(1e6)):
        self.max_size = max_size
        self.ptr = 0
        self.size = 0
        self.device = torch.device(device)
        
        self.action_dim = action_dim
        self.joint_dim = joint_dim
        
        # âœ… æ ‡é‡æ•°æ®å­˜å‚¨ (RAM) - ä»…å‡ ç™¾MB
        self.storage = {
            'joint': np.zeros((max_size, joint_dim), dtype=np.float32),
            'action': np.zeros((max_size, action_dim), dtype=np.float32),
            'next_joint': np.zeros((max_size, joint_dim), dtype=np.float32),
            'reward': np.zeros((max_size, 1), dtype=np.float32),
            'terminal': np.zeros((max_size, 1), dtype=np.float32),
        }
        
        # âœ… ç´¢å¼•æ˜ å°„å­˜å‚¨ (RAM) - è®°å½•æ¯æ¡æ•°æ®åœ¨ HDF5 ä¸­çš„ä½ç½®
        # shape: (max_size, 2) -> [curr_idx, next_idx]
        self.indices_buf = np.zeros((max_size, 2), dtype=np.int32)
        
        # ğŸ’¾ å›¾åƒå…ƒæ•°æ®
        self.image_metadata = {
            'hdf5_path': None,
            'need_transpose': False, # æ ‡è®°åŸå§‹æ•°æ®æ˜¯å¦ä¸º HWC
        }
        
        # ç»Ÿè®¡ä¿¡æ¯ (ä»…ç”¨äºæ—¥å¿—æŸ¥çœ‹ï¼Œä¸å‚ä¸å½’ä¸€åŒ–)
        self.action_mean = None
        self.action_std = None
        self.joint_mean = None
        self.joint_std = None
        
        # æ–‡ä»¶å¥æŸ„ç¼“å­˜
        self._hdf5_cache = {}

    def _get_hdf5_file(self, hdf5_path):
        """è·å–æ–‡ä»¶å¥æŸ„ï¼Œé¿å…é‡å¤æ‰“å¼€"""
        if hdf5_path not in self._hdf5_cache:
            # swmr=True å°è¯•å…è®¸å¹¶å‘è¯»å–æ¨¡å¼
            self._hdf5_cache[hdf5_path] = h5py.File(hdf5_path, 'r', swmr=True, libver='latest')
        return self._hdf5_cache[hdf5_path]

    def _load_and_resize_image(self, hdf5_file, dataset_key, index):
        """
        æ ¸å¿ƒè¯»å–å‡½æ•°ï¼šè¯»å– -> Resize -> Transpose
        ç›®æ ‡è¾“å‡º: (3, 224, 224)
        """
        # è¯»å–åŸå§‹æ•°æ®
        img = hdf5_file[dataset_key][index]
        
        # ç›®æ ‡: HWC (ç”¨äºcv2) -> CHW (ç”¨äºPyTorch)
        if self.image_metadata['need_transpose']:
            # è¾“å…¥åŸæœ¬æ˜¯ HWC (ä¾‹å¦‚ 480x640x3)ï¼Œç›´æ¥ Resize
            img_resized = cv2.resize(img, (224, 224), interpolation=cv2.INTER_LINEAR)
            # HWC -> CHW
            return np.transpose(img_resized, (2, 0, 1))
        else:
            # è¾“å…¥åŸæœ¬æ˜¯ CHW (ä¾‹å¦‚ 3x480x640)ï¼Œå…ˆè½¬ HWC æ‰èƒ½ Resize
            img_hwc = np.transpose(img, (1, 2, 0))
            img_resized = cv2.resize(img_hwc, (224, 224), interpolation=cv2.INTER_LINEAR)
            # HWC -> CHW
            return np.transpose(img_resized, (2, 0, 1))

    def sample(self, batch_size):
        """
        é‡‡æ · Batch
        æ³¨æ„ï¼šè¿™é‡Œä¸å†è°ƒç”¨ normalize_joint/action
        """
        ind = np.random.randint(0, self.size, size=batch_size)
        
        # 1. å‡†å¤‡å›¾åƒè¯»å–
        hdf5_path = self.image_metadata['hdf5_path']
        hdf5_file = self._get_hdf5_file(hdf5_path)
        
        # ç¡®å®š HDF5 ä¸­çš„é”®å
        if 'observations' in hdf5_file:
            obs = hdf5_file['observations']
            left_key = 'left_image' if 'left_image' in obs else 'left_wrist_image'
            right_key = 'right_image' if 'right_image' in obs else 'right_wrist_image'
            global_key = 'global_image'
        else:
            left_key = 'left_image'
            right_key = 'right_image'
            global_key = 'global_image'
        
        # è·å–è¯¥ batch å¯¹åº”çš„ HDF5 ç´¢å¼•
        curr_indices = self.indices_buf[ind, 0]
        next_indices = self.indices_buf[ind, 1]
        
        # é¢„åˆ†é…å†…å­˜ (Batch, 3, 224, 224)
        left_imgs = np.empty((batch_size, 3, 224, 224), dtype=np.uint8)
        right_imgs = np.empty((batch_size, 3, 224, 224), dtype=np.uint8)
        global_imgs = np.empty((batch_size, 3, 224, 224), dtype=np.uint8)
        
        next_left_imgs = np.empty((batch_size, 3, 224, 224), dtype=np.uint8)
        next_right_imgs = np.empty((batch_size, 3, 224, 224), dtype=np.uint8)
        next_global_imgs = np.empty((batch_size, 3, 224, 224), dtype=np.uint8)
        
        # å¾ªç¯è¯»å–å¹¶ Resize (IOå¯†é›†å‹)
        for i in range(batch_size):
            c_idx = curr_indices[i]
            n_idx = next_indices[i]
            
            left_imgs[i] = self._load_and_resize_image(hdf5_file, left_key, c_idx)
            right_imgs[i] = self._load_and_resize_image(hdf5_file, right_key, c_idx)
            global_imgs[i] = self._load_and_resize_image(hdf5_file, global_key, c_idx)
            
            next_left_imgs[i] = self._load_and_resize_image(hdf5_file, left_key, n_idx)
            next_right_imgs[i] = self._load_and_resize_image(hdf5_file, right_key, n_idx)
            next_global_imgs[i] = self._load_and_resize_image(hdf5_file, global_key, n_idx)

        # è½¬æ¢ä¸º Tensor å¹¶ç§»åŠ¨åˆ° GPU
        batch_device = self.device
        
        return (
            torch.FloatTensor(left_imgs).to(batch_device),
            torch.FloatTensor(right_imgs).to(batch_device),
            torch.FloatTensor(global_imgs).to(batch_device),
            
            # æ ‡é‡æ•°æ®ï¼šç›´æ¥è¿”å›ï¼Œä¸åšå½’ä¸€åŒ–
            torch.FloatTensor(self.storage['joint'][ind]).to(batch_device),
            torch.FloatTensor(self.storage['action'][ind]).to(batch_device),
            
            torch.FloatTensor(next_left_imgs).to(batch_device),
            torch.FloatTensor(next_right_imgs).to(batch_device),
            torch.FloatTensor(next_global_imgs).to(batch_device),
            
            # æ ‡é‡æ•°æ®ï¼šç›´æ¥è¿”å›
            torch.FloatTensor(self.storage['next_joint'][ind]).to(batch_device),
            
            torch.FloatTensor(self.storage['reward'][ind]).to(batch_device),
            1.0 - torch.FloatTensor(self.storage['terminal'][ind]).to(batch_device)
        )

    # ğŸš« ç¦ç”¨å½’ä¸€åŒ–å‡½æ•°ï¼Œç›´æ¥è¿”å›åŸå€¼
    def normalize_joint(self, joint): return joint
    def unnormalize_joint(self, joint): return joint
    def normalize_action(self, action): return action
    def unnormalize_action(self, action): return action

    def load_from_hdf5(self, hdf5_path, num_traj=None):
        """
        å‘é‡åŒ–åŠ è½½å…ƒæ•°æ® (ç§’çº§å®Œæˆ)
        """
        print(f"ğŸš€ [Lazy Load] Loading metadata from {hdf5_path} (No Normalization)...")
        
        with h5py.File(hdf5_path, 'r') as f:
            if 'observations' in f:
                obs = f['observations']
                # è¯»å–ç¬¬ä¸€å¼ å›¾æ¥æ£€æµ‹æ ¼å¼
                if 'left_image' in obs: left_sample = obs['left_image'][0]
                else: left_sample = obs['left_wrist_image'][0]
                joints_dset = obs['joint']
            else:
                left_sample = f['left_image'][0]
                joints_dset = f['joint']
            
            actions = f['actions']
            rewards = f['rewards']
            terminals = f['terminals']
            
            total_len = len(actions)
            if num_traj is not None:
                total_len = min(total_len, num_traj)
            
            # æ£€æµ‹æ˜¯å¦éœ€è¦è½¬ç½®: HWC (shape[-1]==3) -> éœ€è¦è½¬ç½®
            need_transpose = (left_sample.shape[-1] == 3)
            
            # è®¡ç®—å®é™…åŠ è½½é‡
            load_len = min(total_len, self.max_size - self.size)
            if load_len <= 0:
                print("âš ï¸ Buffer full, skipping load.")
                return

            print(f"  ğŸ“¥ Loading {load_len} transitions into RAM (Scalars only)...")
            
            start_ptr = self.ptr
            end_ptr = start_ptr + load_len
            
            # å¤„ç† Buffer å›ç¯ (ç®€åŒ–ç‰ˆï¼šå¦‚æœæº¢å‡ºåˆ™æˆªæ–­)
            if end_ptr > self.max_size:
                load_len = self.max_size - start_ptr
                end_ptr = self.max_size
                print(f"  âš ï¸ Truncating load to {load_len} items due to buffer limit.")

            # âœ… å‘é‡åŒ–èµ‹å€¼ï¼šç¬é—´å®Œæˆ
            self.storage['joint'][start_ptr:end_ptr] = joints_dset[:load_len]
            # ç¡®ä¿ joints è¶³å¤Ÿé•¿
            self.storage['next_joint'][start_ptr:end_ptr] = joints_dset[1:load_len+1]
            
            self.storage['action'][start_ptr:end_ptr] = actions[:load_len]
            self.storage['reward'][start_ptr:end_ptr] = rewards[:load_len]
            self.storage['terminal'][start_ptr:end_ptr] = terminals[:load_len]
            
            # ç”Ÿæˆç´¢å¼•æ˜ å°„: (0, 1), (1, 2), ...
            indices = np.arange(load_len, dtype=np.int32)
            self.indices_buf[start_ptr:end_ptr, 0] = indices
            self.indices_buf[start_ptr:end_ptr, 1] = indices + 1
            
            # æ›´æ–°æŒ‡é’ˆ
            self.ptr = (self.ptr + load_len) % self.max_size
            self.size = min(self.size + load_len, self.max_size)
            
            # ä¿å­˜å…ƒæ•°æ®
            self.image_metadata['hdf5_path'] = hdf5_path
            self.image_metadata['need_transpose'] = need_transpose

        self.compute_statistics()
        print(f"âœ… Load Complete. Buffer size: {self.size}")
        print(f"   Image loading: On-the-fly (Resize to 224x224)")
        print(f"   Normalization: DISABLED (Assuming data is pre-normalized)")

    def compute_statistics(self):
        print("Computing statistics (For logging only)...")
        # ä»…è®¡ç®—ç”¨äºæ˜¾ç¤ºï¼Œä¸ç”¨äºå½’ä¸€åŒ–
        self.action_mean = np.mean(self.storage['action'][:self.size], axis=0)
        self.action_std = np.std(self.storage['action'][:self.size], axis=0)
        self.joint_mean = np.mean(self.storage['joint'][:self.size], axis=0)
        self.joint_std = np.std(self.storage['joint'][:self.size], axis=0)